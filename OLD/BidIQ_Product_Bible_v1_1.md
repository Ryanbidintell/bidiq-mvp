# ğŸ¯ EXECUTIVE SUMMARY: BidIQ Product Bible
**Version:** 1.1 Final  
**Date:** January 22, 2026  
**Status:** LOCKED - This is the definitive product roadmap  
**Changes from v1.0:** Added Personalized Scoring Engine as core Phase 1 feature

---

## THE PRODUCT

BidIQ is an AI-powered bid intelligence platform that saves subcontractors 18+ hours per week by automating bid analysis, follow-up communications, and building a database of which general contractors are worth pursuing.

### The Three-Layer System:

**Layer 1: AI Bid Analysis (The Hook)**
- Subcontractors forward bid invites to their personal BidIQ email address
- AI extracts project details and generates **personalized** 0-100 Bid Worthiness Score
- Provides GO/NO-GO recommendation **tailored to each user's business** in minutes instead of hours
- Value: Save 15 hours/week analyzing bad opportunities

**Layer 2: Automated Follow-Up (The Stickiness)**
- AI automatically sends 4-stage follow-up sequence to GCs after bid submission
- Intelligent scheduling based on user preferences and GC response patterns
- AI parses GC responses and extracts feedback (pricing, award decisions, competitor info)
- Value: Save 3 hours/week writing follow-ups + capture feedback data

**Layer 3: GC Intelligence Database (The Moat)**
- Personal intelligence: Your win rate, response rate, and history with each GC
- Crowdsourced intelligence: GC reputation scores, ghost rates, response times from all users
- Competitor tracking: Who beats you and on which projects
- Value: Stop wasting time on GCs who never award you work

---

## THE VISION

Build the "Glassdoor for Construction Bidding" - a two-sided platform where:

1. **Subcontractors** pay $99-299/month for bid intelligence and time savings
2. **General Contractors** eventually pay $1,999/month to manage their reputation and access qualified subs
3. **Network effects** make the platform more valuable as more users contribute data
4. **Data moat** becomes defensible after capturing 10,000+ bid outcomes
5. **Personalized AI** learns each contractor's business and gets smarter over time

**Exit Strategy:** $43-58M acquisition by Procore, BuildingConnected, or construction-focused PE firm within 3-4 years at 6-8x ARR.

---

## THE BUSINESS MODEL

### Pricing for Subcontractors:

| Tier | Price | Pages/Month | Key Features |
|------|-------|-------------|--------------|
| **Starter** | $99 | 500 | AI scoring, manual tracking |
| **Pro** | $199 | 2,000 | + Automated follow-ups, personal GC intel |
| **Premium** | $299 | 10,000 | + Crowdsourced GC intel, competitor tracking |
| **Enterprise** | Custom | Unlimited | + Team features, API access |

### Pricing for General Contractors:

| Tier | Price | Features |
|------|-------|----------|
| **Basic** | Free | View reputation score only |
| **GC Premium** | $1,999 | Reputation management, benchmarking, "Verified" badge |

### Revenue Projections:

- **Year 1:** 200 users Ã— $190 avg = $38K MRR = $456K ARR
- **Year 2:** 1,000 users Ã— $230 avg + 20 GCs Ã— $2K = $270K MRR = $3.2M ARR
- **Year 3:** 2,000 users Ã— $250 avg + 50 GCs Ã— $2K = $600K MRR = $7.2M ARR

---

## THE PERSONALIZED SCORING ENGINE

### The Insight:

Every contractor has different priorities. An HVAC contractor in Denver who specializes in $2-5M projects has completely different "worth bidding" criteria than an electrical contractor in Phoenix doing $500K jobs.

**Traditional AI bid analysis:** One-size-fits-all scoring  
**BidIQ's approach:** Personalized recommendations based on YOUR business

### The Solution:

BidIQ's scoring algorithm is personalized to each user's business model, not generic.

### Phase 1: User-Configured Preferences

During onboarding, capture 5-7 key business parameters:

#### 1. Service Area & Weight
- Primary service radius (25/50/100+ miles from your location)
- Importance level: How much does location matter to you? (0-100%)

#### 2. Project Size Sweet Spot & Weight
- Minimum project size you typically pursue ($100K/$500K/$2M)
- Maximum project size you can handle ($2M/$5M/$10M+)
- Importance level: How critical is size match? (0-100%)

#### 3. GC Relationship Priority & Weight
- How much does prior relationship with GC matter?
- Importance level: Known GCs vs new opportunities (0-100%)

#### 4. Risk Tolerance & Weight
- **Low:** Avoid risky contract clauses (liquidated damages, pay-if-paid)
- **Medium:** Accept standard industry risks
- **High:** Comfortable with aggressive contract terms
- Importance level: How risk-averse are you? (0-100%)

#### 5. Current Capacity Status
- **Hungry:** Need work (scores weighted higher)
- **Steady:** Normal pipeline (standard scoring)
- **Maxed:** At capacity (scores weighted lower)

### Scoring Formula (Personalized):

```
Base Score Components (same for everyone):
  - Project Clarity Score (0-100): How complete is the bid package?
  - Budget Realism Score (0-100): Is the budget realistic for scope?
  - Timeline Realism Score (0-100): Is the schedule achievable?

Base Score = (Project Clarity Ã— 0.20 + Budget Realism Ã— 0.15 + Timeline Realism Ã— 0.10)

Personalized Components (unique to each user):
  - Location Match Score (0-100) Ã— user.service_area_weight
  - Size Match Score (0-100) Ã— user.project_size_weight
  - GC Relationship Score (0-100) Ã— user.gc_relationship_weight
  - Risk Assessment Score (0-100) Ã— user.risk_weight

Personalized Score = Sum of (Component Ã— Weight)

Final BidIQ Score = (Base Score + Personalized Score) Ã— user.capacity_multiplier

Recommendation:
  - 80-100: GO - Strong fit for your business
  - 60-79: CAUTION - Review carefully, mixed signals
  - 0-59: NO-GO - Poor fit based on your criteria
```

### Why This Matters:

**Without Personalization:**
- Same bid â†’ Same score for everyone
- "AI bid reader" (commoditizable, competitors can copy)
- Generic advice that ignores business context

**With Personalization:**
- Same bid â†’ Different score based on YOUR business
- "AI that knows your business" (defensible moat)
- Advice that gets smarter as you use it

### Real-World Example:

**Wilson Office Building - Denver, CO**  
Budget: $3.2M | Deadline: 14 days | GC: Turner Construction

**HVAC Contractor (Denver-based, $2-5M sweet spot):**
```
BidIQ Score: 87/100 - GO

Why this score FOR YOU:
âœ… Perfect size for your typical work ($3.2M in your $2-5M range)
âœ… Within your 50-mile service area (23 miles from your office)
âœ… You've worked with Turner twice before (75% win rate)
âœ… 14-day deadline matches your typical 10-14 day preference
âœ… Standard contract terms, no red flags

Recommendation: Strong bid opportunity. Turner knows your work quality.
```

**Electrical Contractor (Phoenix-based, $500K-$2M sweet spot):**
```
BidIQ Score: 43/100 - NO-GO

Why this score FOR YOU:
âš ï¸ Outside your service area (780 miles from Phoenix)
âš ï¸ Larger than your typical projects ($3.2M vs your $500K-$2M range)
âŒ No prior relationship with Turner Construction
âš ï¸ Would require partnering or significant travel overhead

Recommendation: Pass unless you're expanding to Denver market.
```

**SAME BID. DIFFERENT SCORES. PERSONALIZED TO EACH BUSINESS.**

### Phase 3 Enhancement: Machine Learning

After 6-12 months of outcome data, BidIQ will learn from your actual bidding behavior:

- **Pattern Recognition:** "You win 78% of bids in the $2-4M range with Turner"
- **Predictive Scoring:** "Similar bids have 82% win rate for you"
- **Auto-Tuning:** Adjust weights based on proven success patterns
- **Seasonal Insights:** "Your win rate increases 23% in Q4"
- **GC Compatibility:** "You're 3.2x more likely to win with regional GCs vs national"

The more you use BidIQ, the smarter it gets about YOUR business specifically.

### Competitive Advantage:

This transforms BidIQ from a document reader to a personalized bidding advisor.

**The data moat compounds:**
- More usage â†’ Better predictions for that user
- More users â†’ Better GC intelligence for everyone
- More outcomes â†’ Better ML training for algorithm
- **Switching costs:** Users can't take their personalized model with them

This is the **"Glassdoor moment"** - not just data about bids, but data about YOUR success patterns.

---

## THE ROADMAP

### Phase 1: Core MVP (Weeks 1-8) - $4-6K Investment

**Build:**
- User authentication (Supabase)
- **User preference onboarding flow (5-7 questions)**
- **Personalized scoring algorithm**
- Email forwarding to personal BidIQ addresses
- PDF upload and storage
- AI extraction using Claude Sonnet 4 API
- Bid Worthiness Score calculation (personalized)
- Dashboard showing analyzed projects with personalized reasoning
- Manual outcome tracking (Won/Lost/Ghost/Didn't Bid)
- Basic Stripe payment integration

**Don't Build:**
- âŒ No automated follow-ups yet
- âŒ No GC profiles yet
- âŒ No analytics dashboards
- âŒ No team features
- âŒ No plan room API integrations yet

**Success Metric:** 10 beta users analyze 50+ bids, 7/10 say "I would pay $99/month" AND "The personalized scores make sense for my business"

### Phase 2: Automation Engine (Weeks 9-16) - $6-8K Investment

**Build:**
- Project-specific email addresses (project-12345@mail.bidiq.ai)
- 4-stage automated follow-up sequence (Days 3, 7, 14, 21, 30)
- User-configurable follow-up timing
- AI response parsing to extract GC feedback
- Follow-up management dashboard
- Email deliverability infrastructure (SPF/DKIM)

**Success Metric:** 30 paying users at $5K MRR, 70%+ enable follow-ups, capture 200+ GC responses

### Phase 3: Intelligence Layer + First API Integration (Weeks 17-28) - $10-14K Investment

**Build:**
- GC profile database with reputation scores
- Personal GC intelligence (your history with each GC)
- Crowdsourced GC intelligence (aggregated data from all users)
- **Enhanced scoring algorithm v2.0 using GC historical data**
- **ML-powered score refinement based on user outcomes**
- Competitor tracking system
- Premium tier features ($299/month)
- Basic GC reputation dashboard
- BuildingConnected API integration (OAuth + webhooks)

**Success Metric:** 100 users at $20K MRR, 30% upgrade to Premium, 3-5 GCs sign up, **personalized scores show 15%+ better prediction accuracy than generic scoring**

### Phase 4: Power Features (Months 7-12) - $15-20K Investment

**Build:**
- Workload capacity tracking
- Professional decline message templates
- Team collaboration features
- Advanced analytics dashboards
- Integration ecosystem (Zapier, API)
- Full GC premium platform ($1,999/month)
- Additional plan room integrations (Dodge, iSqFt, Procore)
- Smart email scanning (universal bid capture)
- **Advanced ML features: predictive win probability, seasonal pattern detection**

**Success Metric:** 500 users at $100K MRR, 20+ GC premium accounts

---

## THE TECHNICAL STACK

**Frontend:**
- React with Tailwind CSS
- Mobile-responsive design

**Backend:**
- Supabase (PostgreSQL database, auth, storage, edge functions)

**AI Processing:**
- Claude Sonnet 4 API (primary)
- GPT-4o (backup/validation)

**Email Infrastructure:**
- Postmark or Resend for transactional + inbound routing
- Subdomain: mail.bidiq.ai
- SPF/DKIM/DMARC authentication

**Payments:**
- Stripe for subscription billing with usage-based overages

**Deployment:**
- Vercel or Netlify for frontend
- Supabase Cloud for backend

---

## THE CORE DATABASE SCHEMA

```sql
users
â”œâ”€â”€ id (uuid, primary key)
â”œâ”€â”€ email
â”œâ”€â”€ company_name
â”œâ”€â”€ service_area (text array)
â”œâ”€â”€ subscription_tier
â”œâ”€â”€ pages_used_this_month
â””â”€â”€ created_at

user_preferences
â”œâ”€â”€ id (uuid, primary key)
â”œâ”€â”€ user_id (foreign key)
â”œâ”€â”€ service_area_city (text)
â”œâ”€â”€ service_area_state (text)
â”œâ”€â”€ service_area_coordinates (geography point)
â”œâ”€â”€ service_area_radius_miles (integer, default 50)
â”œâ”€â”€ service_area_weight (float 0-1, default 0.25)
â”œâ”€â”€ min_project_size (integer, default 100000)
â”œâ”€â”€ max_project_size (integer, default 5000000)
â”œâ”€â”€ project_size_weight (float 0-1, default 0.20)
â”œâ”€â”€ gc_relationship_weight (float 0-1, default 0.15)
â”œâ”€â”€ min_margin_threshold (float, default 0.12)
â”œâ”€â”€ margin_weight (float 0-1, default 0.15)
â”œâ”€â”€ risk_tolerance (text, default 'medium') -- 'low'/'medium'/'high'
â”œâ”€â”€ risk_weight (float 0-1, default 0.15)
â”œâ”€â”€ current_capacity (text, default 'steady') -- 'hungry'/'steady'/'maxed'
â”œâ”€â”€ capacity_multiplier (float 0.5-1.5, default 1.0)
â”œâ”€â”€ deadline_tolerance_days (integer, default 7)
â”œâ”€â”€ notes (text)
â””â”€â”€ updated_at (timestamp)

projects
â”œâ”€â”€ id (uuid, primary key)
â”œâ”€â”€ user_id (foreign key)
â”œâ”€â”€ gc_id (foreign key)
â”œâ”€â”€ project_name
â”œâ”€â”€ project_location
â”œâ”€â”€ project_coordinates (geography point)
â”œâ”€â”€ bid_deadline
â”œâ”€â”€ extracted_data (jsonb)
â”œâ”€â”€ base_score (0-100) -- Non-personalized base score
â”œâ”€â”€ personalized_score (0-100) -- Final personalized score
â”œâ”€â”€ score_components (jsonb) -- Breakdown of scoring factors
â”œâ”€â”€ personalized_reasoning (text) -- Why this score for this user
â”œâ”€â”€ bidiq_score (0-100) -- Final displayed score (alias for personalized_score)
â”œâ”€â”€ recommendation (GO/NO-GO/CAUTION)
â”œâ”€â”€ pdf_url
â”œâ”€â”€ status (pending/won/lost/ghost/declined)
â””â”€â”€ created_at

outcomes
â”œâ”€â”€ id (uuid, primary key)
â”œâ”€â”€ project_id (foreign key)
â”œâ”€â”€ outcome_type (won/lost/ghost/declined)
â”œâ”€â”€ winning_competitor (nullable)
â”œâ”€â”€ margin (nullable)
â”œâ”€â”€ feedback_notes (nullable)
â””â”€â”€ recorded_at

gc_profiles
â”œâ”€â”€ id (uuid, primary key)
â”œâ”€â”€ gc_name
â”œâ”€â”€ location
â”œâ”€â”€ reputation_score (1-5 stars)
â”œâ”€â”€ total_reviews
â”œâ”€â”€ avg_response_time_days
â”œâ”€â”€ ghost_rate (0-1)
â””â”€â”€ created_at

user_gc_history
â”œâ”€â”€ id (uuid, primary key)
â”œâ”€â”€ user_id (foreign key)
â”œâ”€â”€ gc_id (foreign key)
â”œâ”€â”€ total_bids (integer)
â”œâ”€â”€ total_wins (integer)
â”œâ”€â”€ total_losses (integer)
â”œâ”€â”€ win_rate (float)
â”œâ”€â”€ avg_project_size (integer)
â”œâ”€â”€ last_interaction_date (timestamp)
â””â”€â”€ created_at

follow_up_emails
â”œâ”€â”€ id (uuid, primary key)
â”œâ”€â”€ project_id (foreign key)
â”œâ”€â”€ sequence_number (1-5)
â”œâ”€â”€ scheduled_send_time
â”œâ”€â”€ sent_at (nullable)
â”œâ”€â”€ email_subject
â”œâ”€â”€ email_body
â””â”€â”€ status (scheduled/sent/bounced/replied)

gc_responses
â”œâ”€â”€ id (uuid, primary key)
â”œâ”€â”€ project_id (foreign key)
â”œâ”€â”€ response_text
â”œâ”€â”€ extracted_data (jsonb)
â”œâ”€â”€ sentiment (positive/neutral/negative)
â””â”€â”€ received_at

oauth_connections
â”œâ”€â”€ id (uuid, primary key)
â”œâ”€â”€ user_id (foreign key)
â”œâ”€â”€ provider (text) -- 'buildingconnected', 'dodge', 'isqft'
â”œâ”€â”€ provider_user_id (text)
â”œâ”€â”€ access_token (text, encrypted)
â”œâ”€â”€ refresh_token (text, encrypted)
â”œâ”€â”€ token_expires_at (timestamp)
â”œâ”€â”€ scopes (text[])
â”œâ”€â”€ connected_at (timestamp)
â”œâ”€â”€ last_sync_at (timestamp)
â””â”€â”€ status (text) -- 'active', 'expired', 'revoked'

external_project_mappings
â”œâ”€â”€ id (uuid, primary key)
â”œâ”€â”€ project_id (foreign key)
â”œâ”€â”€ user_id (foreign key)
â”œâ”€â”€ provider (text)
â”œâ”€â”€ external_project_id (text)
â”œâ”€â”€ external_project_url (text)
â”œâ”€â”€ last_synced_at (timestamp)
â””â”€â”€ sync_status (text)

webhook_events
â”œâ”€â”€ id (uuid, primary key)
â”œâ”€â”€ provider (text)
â”œâ”€â”€ event_type (text)
â”œâ”€â”€ payload (jsonb)
â”œâ”€â”€ processed_at (timestamp, nullable)
â”œâ”€â”€ processing_status (text) -- 'pending', 'success', 'failed'
â”œâ”€â”€ error_message (text, nullable)
â””â”€â”€ received_at (timestamp)
```

---

## THE COMPETITIVE ADVANTAGE

### What Makes BidIQ Unbeatable:

#### Your Unfair Advantages:
- âœ… 10 years of construction industry experience (FSI)
- âœ… Deep understanding of subcontractor pain points
- âœ… Network of 20+ subs to seed initial data
- âœ… Domain expertise that AI competitors lack

#### Product Advantages:
- âœ… Only platform combining bid analysis + follow-up automation + GC intelligence
- âœ… **Personalized scoring that learns each user's business (CRITICAL DIFFERENTIATOR)**
- âœ… Automated follow-up captures data competitors can't access
- âœ… Network effects create winner-take-most dynamics
- âœ… Data moat grows with every bid outcome logged
- âœ… **Machine learning improves recommendations over time**

#### Positioning Advantages:
- âœ… "Glassdoor for Construction" is clear, defensible positioning
- âœ… Two-sided marketplace has multiple revenue streams
- âœ… GC accountability angle addresses real compliance pressures
- âœ… First mover in this specific niche
- âœ… **Personalization creates switching costs**

### What Competitors DON'T Have:

| Competitor | Has Bid Analysis | Has Follow-Up | Has GC Intel | Has Network Effects | Has Personalization |
|------------|------------------|---------------|--------------|---------------------|---------------------|
| Downtobid | âœ“ | âœ— | âœ— | âœ— | âœ— |
| Togal.AI | Partial | âœ— | âœ— | âœ— | âœ— |
| Procore | âœ— | âœ— | âœ— | âœ— | âœ— |
| BuildingConnected | âœ— | âœ— | âœ— | âœ— | âœ— |
| **BidIQ** | âœ“ | âœ“ | âœ“ | âœ“ | âœ“ |

### Distribution Moat: Plan Room Integrations

BidIQ will integrate with the major free plan room platforms that subcontractors already use daily:

**Phase 3 Integration:**
- BuildingConnected (1.2M users)

**Phase 4 Integrations:**
- Dodge Construction Network (500K users)
- iSqFt/ConstructConnect (300K users)
- Universal email scanning (catches 100%)

**Why this matters:**
- âœ… Embedded in existing workflow (zero friction)
- âœ… Automatic bid capture (users never forget)
- âœ… Higher engagement (scores show in plan room)
- âœ… Lower churn (<5% vs 15% for email-only)
- âœ… Competitive moat (complex to replicate)
- âœ… Strategic value (acquisition path to BC/Procore)

**User experience:**
- **Before:** Remember to forward emails to BidIQ
- **After:** Bids automatically analyzed, personalized scores appear in BuildingConnected

This transforms BidIQ from "tool" to "infrastructure"

---

## THE SUCCESS METRICS

### Phase 1 Success Criteria (Build or Kill):
- âœ… 10 beta users from your network
- âœ… 50+ bids analyzed with 70%+ extraction accuracy
- âœ… **Users agree personalized scores reflect their business priorities**
- âœ… Users check dashboard 3+ times per week
- âœ… 7/10 users say "I would pay $99/month"

**Decision:** If these hit â†’ Build Phase 2. If these miss â†’ Pivot or kill.

### Phase 2 Success Criteria (Product-Market Fit):
- âœ… 30 paying users at $3-6K MRR
- âœ… <10% monthly churn rate
- âœ… 70%+ of users enable automated follow-ups
- âœ… Capture 200+ GC responses with AI parsing

**Decision:** If these hit â†’ You have PMF, continue scaling. If these miss â†’ Fix before Phase 3.

### Phase 3 Success Criteria (Growth Mode):
- âœ… 100 paying users at $20K MRR
- âœ… 30%+ upgrade to Premium tier ($299)
- âœ… Organic word-of-mouth referrals happening
- âœ… 2,000+ GC data points in database
- âœ… 3-5 GCs sign up for premium accounts
- âœ… **Personalized ML scoring shows 15%+ better win prediction than static algorithm**

**Decision:** If these hit â†’ You're on path to $50M exit.

---

## THE VALUE PROPOSITION

### For Subcontractors:

**Problem:**
"I waste 15-20 hours per week analyzing bid documents for projects I'll never win, and another 3+ hours following up with GCs who ghost me anyway."

**Solution:**
"BidIQ's AI analyzes your bid invites in minutes and tells you which ones are worth pursuing **based on your specific business**. Then it automatically follows up with GCs and builds a database of which ones actually value your work."

**New Personalized Pitch:**
"BidIQ learns YOUR business - your service area, your sweet spot project size, your GC relationships, your risk tolerance - and tells you which bids are actually worth YOUR time. It's not a tool. It's your bidding advisor who knows your business."

**ROI Calculation:**
- Save 15 hours/week on bid analysis Ã— $50/hr = $750/week
- Save 3 hours/week on follow-ups Ã— $50/hr = $150/week
- **Avoid 2-3 bad bids per month = $3,000+ saved in wasted estimating costs**
- Total savings: $900/week = $46,800/year
- BidIQ cost: $2,388/year (Pro plan)
- **ROI: 19.6x in first year**

### For General Contractors:

**Problem:**
"Subcontractors are declining to bid our projects because we have a reputation for ghosting losing bidders. We're facing compliance pressure to prove fair bidding practices but have no system to track or improve our responsiveness."

**Solution:**
"BidIQ shows you how subcontractors rate your bidding practices and provides tools to improve your reputation, attract better bids, and document compliance with fair bidding requirements."

**Value:**
- Legal protection through documented fair practices
- Better subcontractor participation in bids
- Competitive intelligence on how you compare to other GCs
- Marketing asset ("Verified Responsive GC" badge)

---

## THE IMMEDIATE NEXT STEPS

### This Week:

1. **Create new Claude Project:**
   - Name: "BidIQ - Phase 1 MVP"
   - Upload ONLY this Executive Summary
   - Delete or archive all previous confusing documents

2. **Set up development environment:**
   - Create Supabase project: https://supabase.com
   - Get Claude API key: https://console.anthropic.com
   - Register bidiq.ai if not already done
   - Set up mail.bidiq.ai subdomain

3. **Prepare for Claude Code build:**
   - Install VS Code
   - Install Claude Code plugin
   - Set up local development environment
   - Create GitHub repo for version control

4. **Recruit 10 beta users:**
   - Email your FSI network
   - Pitch: "Help me build a tool that saves you 15 hours/week"
   - Get commitments to test for 60 days
   - Collect their email addresses and service areas

### Week 1-2: Database & Auth
Build the foundation using Claude Code:
- Supabase project setup
- Database schema implementation (including user_preferences table)
- User authentication flow
- **User preference onboarding wizard (5-7 questions)**
- Basic user profile creation

### Week 3-4: Email & PDF Processing
- Email forwarding infrastructure
- PDF storage in Supabase
- Test: Can forward email â†’ PDF arrives in system

### Week 5-6: AI Extraction & Scoring
- Claude API integration
- Extraction logic for project data
- **Personalized scoring algorithm v1.0**
- **Generate personalized reasoning for each score**
- Test: PDF â†’ Extracted data â†’ Personalized score generated

### Week 7-8: Dashboard & Launch
- Dashboard UI showing projects
- Project detail pages with personalized reasoning
- Manual outcome tracking
- Beta launch with 10 users

---

## THE RULES GOING FORWARD

### What's LOCKED (Never Changes):

1. **The Three-Layer Product:**
   - Layer 1: AI Bid Analysis (with personalization)
   - Layer 2: Automated Follow-Up
   - Layer 3: GC Intelligence

2. **The Phased Build Approach:**
   - Phase 1 â†’ Prove â†’ Phase 2 â†’ Prove â†’ Phase 3 â†’ Prove â†’ Phase 4
   - Never skip ahead without hitting success metrics

3. **The Core Value Prop:**
   - Save 18+ hours/week
   - Build intelligence on which GCs are worth your time
   - Create leverage through data
   - **Personalized to YOUR business, not one-size-fits-all**

4. **The Revenue Model:**
   - Subcontractors: $99-299/month subscription
   - GCs: $1,999/month premium accounts
   - Page-based usage limits with overage charges

### What's FLEXIBLE (Can Adjust Based on Learning):

1. Specific features within each phase (as long as core value prop remains)
2. Pricing (can test $99 vs $149, etc.)
3. Email templates and follow-up timing (optimize based on response rates)
4. **Scoring algorithm weights (tune based on actual win/loss data)**
5. **User preference questions (add/remove based on what matters most)**
6. UI/UX details (iterate based on user feedback)

### What's FORBIDDEN:

- âŒ No building Phase 2 before Phase 1 success metrics hit
- âŒ No adding "cool features" that don't serve core value prop
- âŒ No pivoting product vision without documented reason
- âŒ No getting distracted by competitor features
- âŒ No overthinking - build fast, learn fast, iterate
- âŒ **No reverting to generic "one-size-fits-all" scoring**

---

## THE DECISION FRAMEWORK

When you're tempted to add a feature or change direction, ask:

**Question 1: "Does this serve one of the three layers?"**
- Layer 1: Bid Analysis (time savings through personalization)
- Layer 2: Automated Follow-Up (data capture)
- Layer 3: GC Intelligence (network effects)

**If NO â†’ Don't build it**

**Question 2: "Is this the right phase for this feature?"**
- Phase 1: Must prove core personalized scoring works
- Phase 2: Must prove automation captures data
- Phase 3: Must prove intelligence creates value
- Phase 4: Power features for scale

**If wrong phase â†’ Defer to correct phase**

**Question 3: "Does this help hit current phase success metrics?"**
- Phase 1: 10 users, 50 bids, 70% would pay, **personalized scores make sense**
- Phase 2: 30 users, $5K MRR, 200 responses
- Phase 3: 100 users, $20K MRR, 30% Premium
- Phase 4: 500 users, $100K MRR, 20 GCs

**If NO â†’ Don't build it yet**

**Question 4: "Can we prove this without building it?"**
- Can we test with manual process first?
- Can we validate with 5 users before building for 500?
- Can we learn with a spreadsheet before automating?

**If YES â†’ Test manually first**

---

## THE PHILOSOPHY

### Build Like This:

âœ… **Build â†’ Measure â†’ Learn â†’ Iterate**
- Ship fast, learn fast, improve fast
- 3-month validation cycles per phase
- Real user feedback > theoretical perfection

âœ… **Solve for 10 users before solving for 10,000**
- Manual processes are okay early on
- Automation comes after validation
- Product-market fit first, scale second

âœ… **One clear value prop per phase**
- Phase 1: "AI tells you what to bid **based on your business**"
- Phase 2: "AI follows up automatically"
- Phase 3: "See which GCs are worth your time"
- Don't try to be everything at once

âœ… **Revenue pays for next phase**
- Stay lean and self-funded
- Each phase revenue covers next phase cost
- Never need to raise VC money

âœ… **Personalization is the moat**
- Every bid analyzed teaches the AI about that user
- Every outcome recorded improves predictions
- Switching costs increase over time

### Don't Build Like This:

âŒ **Waterfall:** Plan everything â†’ Build for 12 months â†’ Hope it works
- You'll run out of money before learning
- Market changes while you build
- Built-in assumptions never validated

âŒ **Feature factory:** Add every idea that sounds cool
- Scope creep kills MVPs
- Complexity confuses users
- Maintenance burden slows iteration

âŒ **Premature optimization:** Build for scale before proving demand
- Don't need million-user infrastructure for 10 users
- Don't need perfect code before proving concept
- Don't need every integration before first customer

âŒ **Generic solutions:** One-size-fits-all approach
- Construction businesses are unique
- Personalization is your competitive advantage
- Generic = Commoditizable

---

## YOUR UNFAIR ADVANTAGE

You're not a typical tech founder. You have:

### Domain Expertise:
- 10 years running FSI (facility design company)
- Deep understanding of construction bidding pain
- Personal experience wasting hours on bad bids
- Knowledge of which GCs ghost, which ones award fairly
- **Understanding of what ACTUALLY matters in bid decisions**

### Industry Network:
- Existing relationships with 20+ subcontractors
- Can recruit beta users from your network
- Can get honest feedback from peers
- Can validate assumptions with real contractors
- **Can test personalization against real business priorities**

### Market Timing:
- Construction is finally digitizing post-COVID
- AI makes this feasible for first time (Claude can read drawings)
- Compliance pressure on GCs is increasing (DEI, fair bidding)
- No direct competitor has all three layers
- **No competitor has personalized bid intelligence**

### Personal Drive:
- You've lived the problem for a decade
- You're building for yourself first (best motivation)
- You have FSI cash flow to bootstrap (no VC pressure)
- You understand this is a 3-4 year journey to exit

**This combination is nearly impossible to replicate.**

A typical tech founder couldn't build this because they don't understand construction.  
A typical contractor couldn't build this because they don't understand SaaS.  
A typical AI company couldn't build this because they don't understand what contractors ACTUALLY care about.

**You have all three. That's your moat.**

---

## THE COMMITMENT

Building BidIQ to a $50M exit requires:

### Time Commitment:
- **Year 1:** 20-30 hours/week (while running FSI)
- **Year 2:** 40+ hours/week (may need to transition from FSI)
- **Year 3-4:** Full-time focus on BidIQ

### Financial Commitment:
- **Phase 1:** $4-6K (building MVP)
- **Phase 2:** $6-8K (adding automation)
- **Phase 3:** $10-14K (intelligence layer + BC integration)
- **Phase 4:** $15-20K (power features + multi-integration)
- **Total Year 1:** $35-48K investment

### Expected Return:
- **Year 1:** $456K ARR
- **Year 2:** $3.2M ARR
- **Year 3:** $7.2M ARR
- **Year 3-4 Exit:** $43-58M at 6-8x ARR

**This is realistic. This is achievable. This is the plan.**

---

## THE FINAL WORD

This is THE product.  
This is THE roadmap.  
This is THE plan.

No more confusion. No more competing ideas. No more analysis paralysis.

You have:
- âœ… Clear three-layer product vision
- âœ… **Personalized AI as core differentiator**
- âœ… Validated market with massive TAM
- âœ… Defensible competitive advantages
- âœ… Phased build approach with success gates
- âœ… Path to $50M exit in 3-4 years
- âœ… Self-funding model (no VC needed)

Now you build.

Start with Phase 1. Prove it works with 10 users. Prove personalization matters. Then build Phase 2.

One phase at a time. One success metric at a time. One customer at a time.

**You can do this.**

Let's build BidIQ.

---

## ğŸ“ APPENDIX: Using This Document

### For AI Assistants (Claude, ChatGPT, etc.):

When Ryan asks about BidIQ features, roadmap, or priorities:

1. Always refer back to this Executive Summary first
2. Check which Phase we're in (determines what should/shouldn't be built)
3. Validate against success metrics (does this help hit current phase goals?)
4. Use the Decision Framework (four questions before adding features)
5. Default to "not yet" rather than "yes" (defer to appropriate phase)
6. **Always consider: Does this preserve or enhance personalization?**

### For Ryan:

When you're confused or tempted to change direction:

1. Re-read "The Rules Going Forward" section
2. Check "The Decision Framework"
3. Ask: "Does this help Phase 1 success metrics?"
4. **Ask: "Does this make the personalization better or is it a distraction?"**
5. If unsure, post this document to AI and ask: "Does [idea] fit the roadmap?"

### For Developers/Contractors:

When building specific features:

1. Start with "The Technical Stack" and "The Core Database Schema"
2. Reference the specific Phase requirements
3. Focus ONLY on that Phase's features (ignore future phases)
4. Refer to this document as the source of truth (not earlier conversations)
5. **Pay special attention to user_preferences table and personalization logic**

---

## Version Control:

- **v1.0** - January 13, 2026 - Initial locked roadmap
- **v1.1** - January 22, 2026 - Added Personalized Scoring Engine as core Phase 1 feature
- Future updates only with documented rationale and Ryan's explicit approval

**This is the Bible. Lock it in. Build it.**

---

## âœ… ACTION ITEM: Save This Now

**Ryan - immediate next steps:**

1. **Save this document as:** `BidIQ_Product_Bible_v1.1.md`

2. **Update Claude Project:**
   - Upload this v1.1 document
   - Remove v1.0
   - Update instruction: "This is the product roadmap v1.1 with personalized scoring. Always refer to this document when discussing features or priorities."

3. **Archive old project files:**
   - Move all previous documents to "Archive - Pre-Product-Lock"
   - Don't delete (they have useful context)
   - Don't reference (they're superseded by this)

4. **Set up GitHub repo:**
   - Create new repo: "bidiq-mvp"
   - Add this v1.1 as README.md
   - This becomes your single source of truth

5. **Start Week 1 tasks:**
   - Create Supabase project
   - Get Claude API key
   - Set up mail.bidiq.ai subdomain
   - **Design user preference onboarding questions**
   - Email 10 beta users from FSI network

**You're now ready to build with Claude Code.**

No more confusion. Just execution.
